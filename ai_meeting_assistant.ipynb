{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/E8lyLzPNJDWnOlvtQ9YK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliAbdallah21/ai-meeting-assistant/blob/main/ai_meeting_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "id": "PeqrK2IQ0Uuo"
      },
      "outputs": [],
      "source": [
        "# @title Installations\n",
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install gradio\n",
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install langchain-openai\n",
        "!pip install ydantic\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Imports\n",
        "import requests\n",
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n"
      ],
      "metadata": {
        "id": "i-jXhVQo3Mf0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title OpenAI's API Setup\n",
        "# Initialize OpenAI client using your Colab secret\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=userdata.get('OPENAI_API_KEY')) # Using the same model as before, set temperature to 0 for more deterministic output\n",
        "\n"
      ],
      "metadata": {
        "id": "6k-9mxEaAdR-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Function to remove non-ASCII characters\n",
        "def remove_non_ascii(text):\n",
        "    return ''.join(i for i in text if ord(i) < 128)"
      ],
      "metadata": {
        "id": "Nxy0Enn2An5m"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Function to handle user queries by generating responses with OpenAI LLM\n",
        "\n",
        "def product_assistant(ascii_transcript):\n",
        "    system_prompt = \"\"\"You are an intelligent assistant specializing in financial products;\n",
        "    your task is to process transcripts of earnings calls, ensuring that all references to\n",
        "     financial products and common financial terms are in the correct format. For each\n",
        "     financial product or common term that is typically abbreviated as an acronym, the full term\n",
        "    should be spelled out followed by the acronym in parentheses. For example, '401k' should be\n",
        "     transformed to '401(k) retirement savings plan', 'HSA' should be transformed to 'Health Savings Account (HSA)' , 'ROA' should be transformed to 'Return on Assets (ROA)', 'VaR' should be transformed to 'Value at Risk (VaR)', and 'PB' should be transformed to 'Price to Book (PB) ratio'. Similarly, transform spoken numbers representing financial products into their numeric representations, followed by the full name of the product in parentheses. For instance, 'five two nine' to '529 (Education Savings Plan)' and 'four zero one k' to '401(k) (Retirement Savings Plan)'. However, be aware that some acronyms can have different meanings based on the context (e.g., 'LTV' can stand for 'Loan to Value' or 'Lifetime Value'). You will need to discern from the context which term is being referred to  and apply the appropriate transformation. In cases where numerical figures or metrics are spelled out but do not represent specific financial products (like 'twenty three percent'), these should be left as is. Your role is to analyze and adjust financial product terminology in the text. Once you've done that, produce the adjusted transcript and a list of the words you've changed\"\"\"\n",
        "\n",
        "    # Combine prompt and transcript\n",
        "    prompt_input = system_prompt + \"\\n\" + ascii_transcript\n",
        "\n",
        "    # Send to OpenAI\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",  # can be upgraded to gpt-4.1 for more complex transcripts\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt_input}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        top_p=0.6,\n",
        "        max_tokens=512\n",
        "    )\n",
        "\n",
        "    # Return the cleaned-up transcript\n",
        "    return response.choices[0].message.content\n",
        "\n"
      ],
      "metadata": {
        "id": "t6msdrGmArNZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define the prompt template\n",
        "template = \"\"\"\n",
        "Generate meeting minutes and a list of tasks based on the provided context.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Meeting Minutes:\n",
        "- Key points discussed\n",
        "- Decisions made\n",
        "\n",
        "Task List:\n",
        "- Actionable items with assignees and deadlines\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "\n",
        "# Define the chain\n",
        "chain = (\n",
        "    {\"context\": RunnablePassthrough()}  # Pass the transcript as context\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "4JglbtWoA1ge"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Audio transcribtion using whisper tiny\n",
        "def transcript_audio(audio_file):\n",
        "    pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=\"openai/whisper-tiny.en\",\n",
        "    chunk_length_s=30,\n",
        "  )\n",
        "    raw_transcript = pipe(audio_file, batch_size=8)[\"text\"]\n",
        "    ascii_transcript = remove_non_ascii(raw_transcript)\n",
        "    adjusted_transcript = product_assistant(ascii_transcript)\n",
        "    result = chain.invoke({\"context\": adjusted_transcript})\n",
        "    # Write the result to a file for downloading\n",
        "    output_file = \"meeting_minutes_and_tasks.txt\"\n",
        "    with open(output_file, \"w\") as file:\n",
        "        file.write(result)\n",
        "    # Return the textual result and the file for download\n",
        "    return result, output_file\n"
      ],
      "metadata": {
        "id": "92Wcjz8TBFKF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gradio Interface\n",
        "audio_input = gr.Audio(sources=\"upload\", type=\"filepath\", label=\"Upload your audio file\")\n",
        "output_text = gr.Textbox(label=\"Meeting Minutes and Tasks\")\n",
        "download_file = gr.File(label=\"Download the Generated Meeting Minutes and Tasks\")\n",
        "iface = gr.Interface(\n",
        "    fn=transcript_audio,\n",
        "    inputs=audio_input,\n",
        "    outputs=[output_text, download_file],\n",
        "    title=\"AI Meeting Assistant\",\n",
        "    description=\"Upload an audio file of a meeting. This tool will transcribe the audio, fix product-related terminology, and generate meeting minutes along with a list of tasks.\"\n",
        ")\n",
        "iface.launch(server_name=\"0.0.0.0\", server_port=5002)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Jye8tBQLBTaJ",
        "outputId": "d7234098-8852-4e77-f46e-e345fc10ec3e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://26bdf3bf29f180e922.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://26bdf3bf29f180e922.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}